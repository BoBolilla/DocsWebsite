[
  {
    "text": "pytorch",
    "collapsed": true,
    "items": [
      {
        "text": "DataLoader Dataset",
        "link": "/笔记/pytorch/DataLoader Dataset"
      },
      {
        "text": "others",
        "link": "/笔记/pytorch/others"
      },
      {
        "text": "save",
        "link": "/笔记/pytorch/save"
      }
    ],
    "link": "/笔记/pytorch/"
  },
  {
    "text": "其他",
    "collapsed": true,
    "items": [
      {
        "text": "git相关",
        "link": "/笔记/其他/git相关"
      },
      {
        "text": "linux相关",
        "link": "/笔记/其他/linux相关"
      },
      {
        "text": "乱七八糟",
        "link": "/笔记/其他/乱七八糟"
      }
    ]
  },
  {
    "text": "课程内容",
    "collapsed": true,
    "items": [
      {
        "text": "人工智能",
        "link": "/笔记/课程内容/人工智能"
      },
      {
        "text": "深度学习",
        "link": "/笔记/课程内容/深度学习"
      }
    ],
    "link": "/笔记/课程内容/"
  },
  {
    "text": "基础",
    "collapsed": true,
    "items": [
      {
        "text": "数学",
        "link": "/笔记/基础/数学"
      },
      {
        "text": "梯度",
        "link": "/笔记/基础/梯度"
      },
      {
        "text": "电脑开机的过程",
        "link": "/笔记/基础/电脑开机的过程"
      },
      {
        "text": "英语",
        "link": "/笔记/基础/英语"
      },
      {
        "text": "连续可导可微可积",
        "link": "/笔记/基础/连续可导可微可积"
      },
      {
        "text": "项目英语",
        "link": "/笔记/基础/项目英语"
      },
      {
        "text": "微积分",
        "collapsed": true,
        "items": []
      },
      {
        "text": "数据结构",
        "collapsed": true,
        "items": [
          {
            "text": "数据结构",
            "link": "/笔记/基础/数据结构/数据结构"
          },
          {
            "text": "栈算表达式",
            "link": "/笔记/基础/数据结构/栈算表达式"
          }
        ]
      },
      {
        "text": "概率论",
        "collapsed": true,
        "items": [
          {
            "text": "协方差",
            "link": "/笔记/基础/概率论/协方差"
          },
          {
            "text": "正态分布和中心极限定理",
            "link": "/笔记/基础/概率论/正态分布和中心极限定理"
          },
          {
            "text": "贝叶斯公式",
            "link": "/笔记/基础/概率论/贝叶斯公式"
          }
        ]
      },
      {
        "text": "线性代数",
        "collapsed": true,
        "items": [
          {
            "text": "线性代数",
            "link": "/笔记/基础/线性代数/线性代数"
          }
        ]
      }
    ],
    "link": "/笔记/基础/"
  },
  {
    "text": "英语",
    "collapsed": true,
    "items": [
      {
        "text": "How to stop overthinking",
        "link": "/笔记/英语/How to stop overthinking"
      },
      {
        "text": "mess",
        "link": "/笔记/英语/mess"
      },
      {
        "text": "rarely VS really",
        "link": "/笔记/英语/rarely VS really"
      },
      {
        "text": "The Paradise of Palau",
        "link": "/笔记/英语/The Paradise of Palau"
      },
      {
        "text": "Words That Won't Stick",
        "link": "/笔记/英语/Words That Won't Stick"
      },
      {
        "text": "让步状从",
        "link": "/笔记/英语/让步状从"
      }
    ],
    "link": "/笔记/英语/"
  },
  {
    "text": "阅读",
    "collapsed": true,
    "items": [
      {
        "text": "富爸爸穷爸爸",
        "link": "/笔记/阅读/富爸爸穷爸爸"
      }
    ],
    "link": "/笔记/阅读/"
  },
  {
    "text": "深度学习",
    "collapsed": true,
    "items": [
      {
        "text": "Batch Normalization vs Layer Normalization",
        "link": "/笔记/深度学习/Batch Normalization vs Layer Normalization"
      },
      {
        "text": "CNN",
        "link": "/笔记/深度学习/CNN"
      },
      {
        "text": "cuda环境切换",
        "link": "/笔记/深度学习/cuda环境切换"
      },
      {
        "text": "卷积",
        "link": "/笔记/深度学习/卷积"
      },
      {
        "text": "损失函数",
        "link": "/笔记/深度学习/损失函数"
      },
      {
        "text": "数据增广",
        "link": "/笔记/深度学习/数据增广"
      },
      {
        "text": "深度学习硬件",
        "link": "/笔记/深度学习/深度学习硬件"
      },
      {
        "text": "深度学习综述",
        "link": "/笔记/深度学习/深度学习综述"
      },
      {
        "text": "过眼云烟",
        "link": "/笔记/深度学习/过眼云烟"
      },
      {
        "text": "NLP",
        "collapsed": true,
        "items": [
          {
            "text": "BERT",
            "link": "/笔记/深度学习/NLP/BERT"
          },
          {
            "text": "Self-attention",
            "link": "/笔记/深度学习/NLP/Self-attention"
          },
          {
            "text": "Transformer",
            "link": "/笔记/深度学习/NLP/Transformer"
          }
        ]
      },
      {
        "text": "实验",
        "collapsed": true,
        "items": [
          {
            "text": "GhostNet轻量化",
            "link": "/笔记/深度学习/实验/GhostNet轻量化"
          }
        ],
        "link": "/笔记/深度学习/实验/"
      }
    ],
    "link": "/笔记/深度学习/"
  },
  {
    "text": "文献阅读",
    "collapsed": true,
    "items": [
      {
        "text": "索引",
        "link": "/笔记/文献阅读/索引"
      },
      {
        "text": "202507",
        "collapsed": true,
        "items": [
          {
            "text": "Fine-Grained Visual Classification via Internal  Ensemble Learning Transformer",
            "link": "/笔记/文献阅读/202507/Fine-Grained Visual Classification via Internal  Ensemble Learning Transformer"
          },
          {
            "text": "Layer by Layer Uncovering Hidden Representations in Language Models",
            "link": "/笔记/文献阅读/202507/Layer by Layer Uncovering Hidden Representations in Language Models"
          },
          {
            "text": "LightLoc Learning Outdoor LiDAR Localization at Light Speed",
            "link": "/笔记/文献阅读/202507/LightLoc Learning Outdoor LiDAR Localization at Light Speed"
          },
          {
            "text": "TransIFC Invariant Cues-Aware Feature  Concentration Learning for Efficient Fine-Grained  Bird Image Classification",
            "link": "/笔记/文献阅读/202507/TransIFC Invariant Cues-Aware Feature  Concentration Learning for Efficient Fine-Grained  Bird Image Classification"
          }
        ]
      },
      {
        "text": "202510",
        "collapsed": true,
        "items": [
          {
            "text": "Understanding Adversarial Robustness from Feature  Maps of Convolutional Layers",
            "link": "/笔记/文献阅读/202510/Understanding Adversarial Robustness from Feature  Maps of Convolutional Layers"
          },
          {
            "text": "基于因果干预的序列推荐中动态项目倾向偏见建模",
            "link": "/笔记/文献阅读/202510/基于因果干预的序列推荐中动态项目倾向偏见建模"
          },
          {
            "text": "基于路径推理的可解释会话推荐",
            "link": "/笔记/文献阅读/202510/基于路径推理的可解释会话推荐"
          },
          {
            "text": "通过MarkovBlanket提升知识追踪的性能和可解释性",
            "link": "/笔记/文献阅读/202510/通过MarkovBlanket提升知识追踪的性能和可解释性"
          }
        ]
      }
    ],
    "link": "/笔记/文献阅读/"
  },
  {
    "text": "生成式人工智能",
    "collapsed": true,
    "items": [
      {
        "text": "Generative AI",
        "collapsed": true,
        "items": [
          {
            "text": "第1讲：生成式AI是什么？",
            "link": "/笔记/生成式人工智能/Generative AI/第1讲：生成式AI是什么？"
          },
          {
            "text": "第2讲：从'工具'从'工具人'",
            "link": "/笔记/生成式人工智能/Generative AI/第2讲：从'工具'从'工具人'"
          },
          {
            "text": "第3讲：你可以训练你自己",
            "link": "/笔记/生成式人工智能/Generative AI/第3讲：你可以训练你自己"
          },
          {
            "text": "第4讲： 大型语言模型的训练过程",
            "link": "/笔记/生成式人工智能/Generative AI/第4讲： 大型语言模型的训练过程"
          }
        ],
        "link": "/笔记/生成式人工智能/Generative AI/"
      },
      {
        "text": "生成式AI时代下的机器学习",
        "collapsed": true,
        "items": [
          {
            "text": "HW1 RAG with Agentic System",
            "link": "/笔记/生成式人工智能/生成式AI时代下的机器学习/HW1 RAG with Agentic System"
          },
          {
            "text": "第1讲：生成式AI的技术突破和未来发展",
            "link": "/笔记/生成式人工智能/生成式AI时代下的机器学习/第1讲：生成式AI的技术突破和未来发展"
          },
          {
            "text": "第2讲：AI agent",
            "link": "/笔记/生成式人工智能/生成式AI时代下的机器学习/第2讲：AI agent"
          },
          {
            "text": "第3讲：模型语言内部运行机制",
            "link": "/笔记/生成式人工智能/生成式AI时代下的机器学习/第3讲：模型语言内部运行机制"
          }
        ]
      }
    ]
  },
  {
    "text": "科研",
    "collapsed": true,
    "items": [
      {
        "text": "method",
        "link": "/笔记/科研/method"
      },
      {
        "text": "偶遇的知识点",
        "link": "/笔记/科研/偶遇的知识点"
      },
      {
        "text": "英语表达",
        "link": "/笔记/科研/英语表达"
      },
      {
        "text": "论文检索网站",
        "link": "/笔记/科研/论文检索网站"
      },
      {
        "text": "方法",
        "collapsed": true,
        "items": [
          {
            "text": "检索式构建",
            "link": "/笔记/科研/方法/检索式构建"
          }
        ]
      }
    ],
    "link": "/笔记/科研/"
  },
  {
    "text": "算法",
    "collapsed": true,
    "items": [
      {
        "text": "auto i与auto& i",
        "link": "/笔记/算法/auto i与auto& i"
      },
      {
        "text": "heap",
        "link": "/笔记/算法/heap"
      },
      {
        "text": "Lambda 表达式",
        "link": "/笔记/算法/Lambda 表达式"
      },
      {
        "text": "连通块",
        "link": "/笔记/算法/连通块"
      },
      {
        "text": "题解",
        "collapsed": true,
        "items": [
          {
            "text": "最小覆盖子串",
            "link": "/笔记/算法/题解/最小覆盖子串"
          },
          {
            "text": "螺旋矩阵",
            "link": "/笔记/算法/题解/螺旋矩阵"
          }
        ]
      }
    ],
    "link": "/笔记/算法/"
  }
]