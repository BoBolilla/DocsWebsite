# 索引

## 细粒度分类

### [Fine-Grained Visual Classification via Internal  Ensemble Learning Transformer](./202507/Fine-Grained%20Visual%20Classification%20via%20Internal%20%20Ensemble%20Learning%20Transformer.md)

IEEE Transactions on Multimedia (TMM) ,2023

* **多头注意力弱学习器集成（投票机制）**--->解决层内头间性能不均衡，识别图像更多的局部关键部位，找到重要的关键的特征
* **跨层融合**抑制噪声，增强特征表达，在于如何更好的跨层融合。 --->层间融合性能问题
* 动态调整各层的token选择数量，增强表现好的层，抑制表现差的层

### [TransIFC Invariant Cues-Aware Feature  Concentration Learning for Efficient Fine-Grained  Bird Image Classification](./202507/TransIFC%20Invariant%20Cues-Aware%20Feature%20%20Concentration%20Learning%20for%20Efficient%20Fine-Grained%20%20Bird%20Image%20Classification)

IEEE Transactions on Multimedia (TMM) ,2023

1. 找关键特征--->[**只要输出特征中区分度最大的前K个特征**](./202507/TransIFC%20Invariant%20Cues-Aware%20Feature%20%20Concentration%20Learning%20for%20Efficient%20Fine-Grained%20%20Bird%20Image%20Classification#FFA)：计算每个特征之间的相似度，求和倒数，分数大说明区分度更大，不普通；分数小说明这个特征没有说明特色，不重要。
2. 低层（包含更多细节）和高层（包含更多语义）的[信息融合](./202507/TransIFC%20Invariant%20Cues-Aware%20Feature%20%20Concentration%20Learning%20for%20Efficient%20Fine-Grained%20%20Bird%20Image%20Classification#HSFA)。
3. 鸟类图像中的**不变线索**（除了眼睛鸟喙等还包括**长距离语义关系**，翅膀&鸟喙位置关系）和**细微差异**。

## 推荐

### Sequential Recommendation

> 已知用户的、长期积累的、按时间顺序排列的完整行为序列，来预测该用户下一个可能感兴趣的项目。它旨在建模用户长期且稳定的个性化兴趣。

#### :pencil: :heart::triangular_flag_on_post:[Modeling dynamic item tendency bias in sequential recommendation with causal intervention](./202510/基于因果干预的序列推荐中动态项目倾向偏见建模.md)

IEEE TKDE ，2024，Modeling dynamic item tendency bias in sequential recommendation with causal intervention

对于推荐序列提出了一种新偏差"动态项目倾向偏差"，使用**因果干预**方法取出混杂干扰因素，并合理利用动态倾向中有利的部分

> 引言我很喜欢，可以模仿，适合“**提出一个新问题并解决**”这样的文章写作
>
> 以及rw，当前该方向有哪几类并展开解释，很标准感觉，适合仿写
>
> 图表解释

### Session-based Recommendation

> 输入是用户在当前一次交互“会话”中的匿名行为序列。
>
> 短期性、实时性、匿名性、动态演化性

#### [Explainable Session-based Recommendation  via Path Reasoning](./202510/基于路径推理的可解释会话推荐.md)

IEEE TKDE, 2024, Yang Cao; Shuo Shang; Jun Wang; Wei Zhang

可解释推荐、基于会话的推荐、分层强化学习（融合市面上方法的优点）、知识图谱（针对起点单一找多个起点）；利用大模型api提取图像特征（额外信息）加入到训练中；

> **多个模块合并形成一个大的模块**，如何进行**实验**（总体、消融、参数、解释）可参考这一篇

## 其他

### [Improving the performance and explainability of knowledge tracing via markov blanket](./202510/通过MarkovBlanket提升知识追踪的性能和可解释性.md)

IPM；Bo Jiang; Yuang Wei; Ting Zhang; Wei Zhang，2024

可解释性：相关性===>**因果关系** （选择合适的输入特征）;

对于知识追踪技术，提出了一种基于markov blanket和FGES框架的算法，提取出对目标参数的一个**因果特征子集（MB）**（有**因果关系**），将该自己输入到一些可解释性强的模型（LR、RF、DT）进行知识追踪。**方法简单有效**

> **实验数据分析**和讨论（**Discussion**）部分写的好，可以参考

### [Understanding Adversarial Robustness from Feature  Maps of Convolutional Layers](./202510/Understanding Adversarial Robustness from Feature  Maps of Convolutional Layers)

IEEE TNNLS,Cong Xu; Wei Zhang; Jun Wang; Min Yang,2024

对于平均池化层，**扩大其特征图尺寸**（上采样、缩短步长）可以提到网络对抗鲁棒性。**方法简单有效**

> 实验设计完善（对比实验、展示方法优势），可以参考实验思路

### [Layer by Layer Uncovering Hidden Representations in Language Models](./202507/Layer%20by%20Layer%20Uncovering%20Hidden%20Representations%20in%20Language%20Models.md)

ICML, Oscar Skean 、Md Rifat Arefin、Dan Zhao 、 Niket Patel 、Jalal Naghiyev 、Yann LeCun 、Ravid Shwartz-Ziv, 2025.2

用一个统一框架矩阵熵（信息论、几何、不变性  ）来证明中间层比最终层提供更有用的特征对于下游任务：中间层在**信息压缩和噪声抑制方面**找到了更好的平衡点，而最后一层可能会变得过于专业化于预训练目标

### LiDAR视觉定位

#### [LightLoc Learning Outdoor LiDAR Localization at Light Speed](./202507/LightLoc%20Learning%20Outdoor%20LiDAR%20Localization%20at%20Light%20Speed.md)

cvpr2025, xmu

轻量化

* 多种不同场景训练一个主干网络，N个MLP，每个MLP对于一个场景，并行训练迫使主干网络学到通用的泛化特征。
* **很多样本相似，容易混淆**，模型训练不易收敛：给模型特征加一个自己**大概在某个位置**先验条件。将样本聚类后重新定义标签，做一个简单的分类任务，得到一个条件概率，拼接到样本特征上。
* **样本中存在大量重复**，有些样本模型反复学过，可以不要。计算epoch间一个滑动窗口内损失的方差，如果方差大说明模型预测不稳定，还要学；反之，不用学可以丢掉。方差降序筛选。

## 解释

 :triangular_flag_on_post: unfinished

:question: leave a question open

:heart: like

:pencil: writing
