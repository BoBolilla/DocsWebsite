# 循环神经网络

## 序列模型

### 核心概念
- 处理随时间变化的数据序列
- 现实场景中的序列数据具有动态特性（非固定不变）

### 现实场景案例
#### 电影评分动态性
- **锚定效应**：基于他人意见调整评分（如奥斯卡效应），持续数月
- **享乐适应**：快速适应新标准后对后续作品期望值变化
- **季节性**：特定时段的内容偏好（如圣诞电影）
- **社会因素**：制作团队负面新闻影响评分
- **cult电影**：因特殊原因形成的小众喜好（如《Plan 9》《Troll 2》）

#### 其他领域
- **用户行为**：程序使用的时间规律性（学生放学后的社交媒体使用）
- **股价预测**：
  - 外推法（预测未来）比内插法（估计历史间值）更困难
- **连续性数据**：
  - 音乐/语音/文本/视频的序列顺序决定意义（如"狗咬人"vs"人咬狗"）
- **自然灾害**：地震的时空相关性（余震的时空聚集性）
- **社交互动**：微博讨论的连续性特征

### 统计工具
#### 基本概念
- 用$x_t$表示时间步$t$的观测值（如股价）
- 预测目标：$P(x_t | x_{t-1},...,x_1)$

#### 两种建模策略
1. **自回归模型(Autoregressive Models)**
   - 使用固定长度$\tau$的历史窗口：$x_{t-1},...,x_{t-\tau}$
   - 参数数量恒定，适合深度网络训练

2. **隐变量自回归模型(Latent Autoregressive Models)**
   - 维护隐藏状态$h_t$总结历史信息
   - 更新规则：
     - $\hat{x}_t = P(x_t | h_t)$
     - $h_t = g(h_{t-1}, x_{t-1})$

#### 训练假设
- 序列动力学保持稳定（静止性假设）
- 完整序列概率分解：
$$P(x_1,...,x_T) = \prod_{t=1}^T P(x_t | x_{t-1},...,x_1)$$

#### 马尔可夫模型
- 当$\tau=1$时为一阶马尔可夫模型：
$$P(x_1,...,x_T) = \prod_{t=1}^T P(x_t | x_{t-1})$$
- 离散值时可用动态规划高效计算

#### 因果关系
- 时间方向性重要：未来不能影响过去
- 正向预测$P(x_{t+1}|x_t)$比反向$P(x_t|x_{t+1})$更合理

### 实践训练
#### 数据生成
- 使用含噪声的正弦波生成1000个时间步数据
- 创建特征-标签对（窗口大小$\tau=4$）

#### 模型架构
- 两层MLP（隐藏层10个单元，ReLU激活）
- 平方损失函数
- 训练5个epoch（loss从0.076降至0.051）

#### 预测表现
1. **单步预测**：效果良好
2. **多步预测**：
   - 误差累积导致预测质量迅速下降
   - 超过16步的预测基本失效

### 关键结论
1. 内插法比外推法更容易
2. 训练时应保持时间顺序（避免用未来数据预测过去）
3. 预测步长增加会快速累积误差

## 8.2 文本预处理

### 处理流程
1. **读取文本**：
   - 示例：《时间机器》数据集（3221行文本）
2. **词元化**：
   - 支持两种粒度：单词级/字符级
3. **构建词表**：
   - 统计词频分配索引
   - 包含特殊token（`<unk>`, `<pad>`等）
4. **转换索引**：
   - 将文本转为数字序列

### 实现细节
- 字符级处理更适合小规模数据
- 最终语料库：170,580个字符，28个唯一字符
<br><br>